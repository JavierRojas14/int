{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nEste programa permite analizar los movimientos de entrada/salida del SCI. El objetivo de este\\nprograma es organizar los artículos según su porcentaje de salida, y así identificar los que tienen\\nmás movimientos. \\n\\nSe obtiene un cuociente entre las Salidas/Entradas. Este es un porcentaje de movimientos. Por \\nejemplo:\\n\\n- Un Valor de 0.86 significa que el 86% de los artículos han salido.\\n\\nPara este efecto, se genera una tabla del estilo:\\nCodigo_Articulo | Nombre_Articulo | Entradas | Salidas\\n\\nLo anterior se logra agrupando las tablas según su código. Los códigos que SÓlO tienen salidas, y \\n0 entradas, significa que en años anteriores tuvieron una entrada. Estos casos serán revisados \\ndespués.\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Este programa permite analizar los movimientos de entrada/salida del SCI. El objetivo de este\n",
    "programa es organizar los artículos según su porcentaje de salida, y así identificar los que tienen\n",
    "más movimientos. \n",
    "\n",
    "Se obtiene un cuociente entre las Salidas/Entradas. Este es un porcentaje de movimientos. Por \n",
    "ejemplo:\n",
    "\n",
    "- Un Valor de 0.86 significa que el 86% de los artículos han salido.\n",
    "\n",
    "Para este efecto, se genera una tabla del estilo:\n",
    "Codigo_Articulo | Nombre_Articulo | Entradas | Salidas\n",
    "\n",
    "Lo anterior se logra agrupando las tablas según su código. Los códigos que SÓlO tienen salidas, y \n",
    "0 entradas, significa que en años anteriores tuvieron una entrada. Estos casos serán revisados \n",
    "después.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtener_full_path(directorio):\n",
    "    return [os.path.join(directorio, file) for file in os.listdir(directorio)]\n",
    "\n",
    "def separar_por_cuartil(df_a_separar, columna_a_separar):\n",
    "    qmin = df_a_separar[columna_a_separar].quantile(0)\n",
    "    q1 = df_a_separar[columna_a_separar].quantile(0.25)\n",
    "    q2 = df_a_separar[columna_a_separar].quantile(0.5)\n",
    "    q3 = df_a_separar[columna_a_separar].quantile(0.75)\n",
    "    qmax = df_a_separar[columna_a_separar].quantile(1)\n",
    "\n",
    "    df_min_q1 = df_a_separar.query(\n",
    "        f'`{columna_a_separar}` >= @qmin and `{columna_a_separar}` < @q1')\n",
    "    df_q1_q2 = df_a_separar.query(\n",
    "        f'`{columna_a_separar}` >= @q1 and `{columna_a_separar}` < @q2')\n",
    "    df_q2_q3 = df_a_separar.query(\n",
    "        f'`{columna_a_separar}` >= @q2 and `{columna_a_separar}` < @q3')\n",
    "    df_q3_max = df_a_separar.query(\n",
    "        f'`{columna_a_separar}` >= @q3 and `{columna_a_separar}` <= @qmax')\n",
    "\n",
    "    return (df_min_q1, df_q1_q2, df_q2_q3, df_q3_max)\n",
    "\n",
    "def rankear_y_plottear(df, eje_x, eje_y, titulo_grafico, numero_ranking):\n",
    "    '''Esta función ordena los datos segun el eje y que se quiere plottear'''\n",
    "    df_ordenada = df.sort_values(eje_y)\n",
    "    diez_mas_altos = df.head(numero_ranking)\n",
    "    diez_mas_bajos = df.tail(numero_ranking)\n",
    "\n",
    "    mosaico = '''\n",
    "    AB\n",
    "    AC\n",
    "    '''\n",
    "    plot_args = [df, eje_x, eje_y, titulo_grafico]\n",
    "\n",
    "    fig, axis = plt.subplot_mosaic(mosaico, figsize=(19.2, 20), layout='constrained')\n",
    "    sns.barplot(data=plot_args[0], x=plot_args[1], y=plot_args[2], ax=axis['A'])\n",
    "\n",
    "    axis['A'].xaxis.set_major_formatter('{x:,}')\n",
    "    axis['A'].tick_params(axis='x', rotation=45)\n",
    "    axis['A'].xaxis.tick_top()\n",
    "\n",
    "    tabla_mas_altos = axis['B'].table(cellText=diez_mas_altos.values,\n",
    "                                      colLabels=diez_mas_altos.columns,\n",
    "                                      loc='center')\n",
    "    tabla_mas_altos.scale(1, 2.3)\n",
    "    tabla_mas_altos.auto_set_font_size(False)\n",
    "    tabla_mas_altos.set_fontsize(10)\n",
    "\n",
    "\n",
    "    tabla_mas_bajos = axis['C'].table(cellText=diez_mas_bajos.values,\n",
    "                                      colLabels=diez_mas_bajos.columns,\n",
    "                                      loc='center')\n",
    "    \n",
    "    tabla_mas_bajos.scale(1, 2.3)\n",
    "    tabla_mas_bajos.auto_set_font_size(False)\n",
    "    tabla_mas_bajos.set_fontsize(10)\n",
    "\n",
    "    axis['B'].set_title('Top 10 gasto Neto')\n",
    "    axis['C'].set_title('Bottom 10 gasto Neto')\n",
    "    axis['B'].axis('off')\n",
    "    axis['C'].axis('off')\n",
    "\n",
    "    fig.suptitle(plot_args[3])\n",
    "    plt.close()\n",
    "\n",
    "    return fig\n",
    "\n",
    "def analizar_distribucion_de_datos(df, columna_a_analizar, titulo_grafico):\n",
    "    serie_columna = df[columna_a_analizar]\n",
    "    descripcion_serie_columna = serie_columna.describe().to_frame().reset_index()\n",
    "    descripcion_serie_columna = descripcion_serie_columna.rename(columns={'index': 'Estadisticas'})\n",
    "\n",
    "    mosaico = '''\n",
    "              AB\n",
    "              AC\n",
    "              '''\n",
    "\n",
    "    fig, axis = plt.subplot_mosaic(mosaico, figsize=(19.2, 10.8), layout='constrained')\n",
    "    args_plot = [df, columna_a_analizar, titulo_grafico]\n",
    "\n",
    "    tabla = axis['A'].table(cellText=descripcion_serie_columna.values,\n",
    "                            colLabels=descripcion_serie_columna.columns, loc='center')\n",
    "    axis['A'].axis('off')\n",
    "\n",
    "    sns.histplot(data=args_plot[0], x=args_plot[1], ax=axis['B'])\n",
    "    sns.boxplot(data=args_plot[0], x=args_plot[1], ax=axis['C'])\n",
    "\n",
    "    plt.ticklabel_format(style='plain', axis='x')\n",
    "\n",
    "    axis['B'].tick_params(axis='x', rotation=45)\n",
    "    axis['C'].tick_params(axis='x', rotation=45)\n",
    "    axis['B'].xaxis.set_major_formatter('{x:,}')\n",
    "    axis['C'].xaxis.set_major_formatter('{x:,}')\n",
    "\n",
    "    fig.suptitle(args_plot[2])\n",
    "    plt.close()\n",
    "\n",
    "    return fig\n",
    "\n",
    "def analisis_global_y_cuartil(df_agrupada, eje_x_agrupado):\n",
    "    imagenes_a_guardar = {}\n",
    "    dfs_a_guardar = {}\n",
    "\n",
    "    fig_rank_global = rankear_y_plottear(\n",
    "        df_agrupada, 'Porcentaje_salidas', eje_x_agrupado, 'Gasto por Servicio Global - Porcentaje_salidas', 10)\n",
    "    fig_distribucion_global = analizar_distribucion_de_datos(\n",
    "        df_agrupada, 'Porcentaje_salidas', 'Distribución Gasto Porcentaje_salidas por Servicio Global')\n",
    "    imagenes_a_guardar['Global'] = [fig_rank_global, fig_distribucion_global]\n",
    "    dfs_a_guardar['Global'] = [df_agrupada]\n",
    "\n",
    "    cuartiles = separar_por_cuartil(df_agrupada, 'Porcentaje_salidas')\n",
    "    for i, cuartil in enumerate(cuartiles):\n",
    "        if not cuartil.empty:\n",
    "            fig_rank_cuartil = rankear_y_plottear(\n",
    "                cuartil, 'Porcentaje_salidas', eje_x_agrupado, f'Gasto por Servicio Intervalo Cuartil {i}', 10)\n",
    "            fig_distribucion_cuartil = analizar_distribucion_de_datos(\n",
    "                cuartil, 'Porcentaje_salidas', f'Distribución Gasto Neto Intervalo Cuartil {i}')\n",
    "            imagenes_a_guardar[i] = [fig_rank_cuartil, fig_distribucion_cuartil]\n",
    "            dfs_a_guardar[i] = [cuartil]\n",
    "    \n",
    "    return imagenes_a_guardar, dfs_a_guardar\n",
    "\n",
    "\n",
    "def guardar_imagenes(imagenes_a_guardar, carpeta_a_guardar):\n",
    "    for intervalo_imagen, lista_imagenes in imagenes_a_guardar.items():\n",
    "        diccionario_intervalos = {'Global': 'Global', 0: 'INTERVALO_1_min_Q1',\n",
    "                                  1: 'INTERVALO_2_Q1_Q2', 2: 'INTERVALO_3_Q2_Q3',\n",
    "                                  3: 'INTERVALO_4_Q3_max'}\n",
    "        path_nueva_carpeta = os.path.join(carpeta_a_guardar, diccionario_intervalos[intervalo_imagen])\n",
    "        try:\n",
    "            os.makedirs(path_nueva_carpeta)\n",
    "        except FileExistsError:\n",
    "            pass\n",
    "\n",
    "        for i, imagen in enumerate(lista_imagenes):\n",
    "            diccionario_nombres = {0: 'ranking', 1: 'distribucion'}\n",
    "            tipo_archivo = diccionario_nombres[i]\n",
    "            nombre_archivo = f'{diccionario_intervalos[intervalo_imagen]}_{tipo_archivo}.svg'\n",
    "            ruta_archivo = os.path.join(path_nueva_carpeta, nombre_archivo)\n",
    "            imagen.savefig(ruta_archivo)\n",
    "\n",
    "def guardar_dfs(dfs_a_guardar, carpeta_a_guardar):\n",
    "    for intervalo_df, lista_dfs in dfs_a_guardar.items():\n",
    "        diccionario_intervalos = {'Global': 'Global', 0: 'INTERVALO_1_min_Q1',\n",
    "                                  1: 'INTERVALO_2_Q1_Q2', 2: 'INTERVALO_3_Q2_Q3',\n",
    "                                  3: 'INTERVALO_4_Q3_max'}\n",
    "        \n",
    "        path_nueva_carpeta = os.path.join(carpeta_a_guardar, diccionario_intervalos[intervalo_df])\n",
    "        try:\n",
    "            os.makedirs(path_nueva_carpeta)\n",
    "        except FileExistsError:\n",
    "            pass\n",
    "\n",
    "        for df in lista_dfs:\n",
    "            nombre_archivo = f'{diccionario_intervalos[intervalo_df]}.xlsx'\n",
    "            ruta_archivo = os.path.join(path_nueva_carpeta, nombre_archivo)\n",
    "            df.to_excel(ruta_archivo, index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(map(lambda x: pd.read_csv(x, parse_dates=[\n",
    "               0], dayfirst=True), obtener_full_path('input')))\n",
    "df_movimientos = df.sort_values('Fecha')\n",
    "df_movimientos.columns = df_movimientos.columns.str.replace(' ', '_')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "movimientos_entrada = df_movimientos.query('Movimiento == \"Entrada\"')\n",
    "movimientos_salida = df_movimientos.query('Movimiento == \"Salida\"')\n",
    "\n",
    "suma_entradas = movimientos_entrada.groupby(by=['Codigo_Articulo', 'Nombre']).sum().reset_index()\n",
    "suma_salidas = movimientos_salida.groupby(by=['Codigo_Articulo', 'Nombre']).sum().reset_index()\n",
    "\n",
    "suma_entradas['Tipo_Movimiento'] = 'Entrada'\n",
    "suma_salidas['Tipo_Movimiento'] = 'Salida'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "entradas_salidas = pd.merge(suma_entradas, suma_salidas, how='outer', on='Codigo_Articulo',\n",
    "                            suffixes=('_entradas', '_salidas'))\n",
    "\n",
    "entradas_salidas = entradas_salidas[[\n",
    "    'Codigo_Articulo', 'Nombre_entradas', 'Nombre_salidas', 'Cantidad_entradas', 'Cantidad_salidas']]\n",
    "\n",
    "entradas_salidas['Porcentaje_salidas'] = entradas_salidas['Cantidad_salidas'] / entradas_salidas['Cantidad_entradas']\n",
    "entradas_salidas = entradas_salidas.sort_values('Porcentaje_salidas')\n",
    "entradas_salidas_validas = entradas_salidas.dropna(subset='Porcentaje_salidas') \\\n",
    "                                           .drop(columns=['Nombre_salidas'])\n",
    "\n",
    "entradas_salidas_validas = entradas_salidas_validas.round(2)\n",
    "entradas_salidas_validas['Nombre_entradas'] = entradas_salidas_validas['Nombre_entradas'].str[:40]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "bajo_100 = entradas_salidas_validas.query('Porcentaje_salidas < 1')\n",
    "sobre_100 = entradas_salidas_validas.query('Porcentaje_salidas >= 1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagenes, dfs = analisis_global_y_cuartil(bajo_100, eje_x_agrupado='Nombre_entradas')\n",
    "carpeta_a_guardar = os.path.join('output', 'ranking_salida_articulos_bajo_100')\n",
    "guardar_imagenes(imagenes, carpeta_a_guardar=carpeta_a_guardar)\n",
    "guardar_dfs(dfs, carpeta_a_guardar=carpeta_a_guardar)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gmolina\\AppData\\Local\\Temp\\ipykernel_33372\\3882483041.py:139: UserWarning: Glyph 9 (\t) missing from current font.\n",
      "  imagen.savefig(ruta_archivo)\n"
     ]
    }
   ],
   "source": [
    "imagenes_sobre_100, dfs_sobre_100 = analisis_global_y_cuartil(sobre_100, eje_x_agrupado='Nombre_entradas')\n",
    "carpeta_a_guardar = os.path.join('output', 'ranking_salida_articulos_sobre_100')\n",
    "guardar_imagenes(imagenes_sobre_100, carpeta_a_guardar=carpeta_a_guardar)\n",
    "guardar_dfs(dfs_sobre_100, carpeta_a_guardar=carpeta_a_guardar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "01515e38d2d4c9d68a7cdf4111cc430df5b00f8319213d00f2225d05549d76c7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
